{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 원핫인코딩한 csv파일 읽기\n",
    "DATA = pd.read_csv(r\"C:/Users/dong/Desktop/R/data/Onehot.csv\" , encoding = \"CP949\" , sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train :  (740781, 117)\n",
      "y_train :  (740781,)\n",
      "X_test :  (246928, 117)\n",
      "y_train :  (246928,)\n"
     ]
    }
   ],
   "source": [
    "## train , test 데이터로 분류\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train , X_test , y_train , y_test = train_test_split(\n",
    "DATA.drop('DLY', axis=1) , DATA['DLY'] , random_state = 0)\n",
    "print(\"X_train : \" , X_train.shape)\n",
    "print(\"y_train : \" , y_train.shape)\n",
    "print(\"X_test : \" , X_test.shape)\n",
    "print(\"y_train : \" , y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 :  0.8796351418300415\n",
      "테스트 :  0.8795478844035508\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.94    217173\n",
      "           1       0.83      0.00      0.00     29755\n",
      "\n",
      "    accuracy                           0.88    246928\n",
      "   macro avg       0.86      0.50      0.47    246928\n",
      "weighted avg       0.87      0.88      0.82    246928\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##모델 적용해보기\n",
    "\n",
    "# 로지스틱  \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = LogisticRegression(C = 1).fit(X_train , y_train)\n",
    "pred_log = logreg.predict(X_test)\n",
    "print(\"훈련 : \" , logreg.score(X_train , y_train))\n",
    "print(\"테스트 : \" , logreg.score(X_test , y_test))\n",
    "print(classification_report(y_test , pred_log))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 :  0.991251125501329\n",
      "테스트 :  0.8794466403162056\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.98      0.93    217173\n",
      "           1       0.50      0.13      0.21     29755\n",
      "\n",
      "    accuracy                           0.88    246928\n",
      "   macro avg       0.70      0.56      0.57    246928\n",
      "weighted avg       0.84      0.88      0.85    246928\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 랜덤 포레스트1\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "forest = RandomForestClassifier(n_estimators = 20 , random_state = 0)\n",
    "forest.fit(X_train , y_train)\n",
    "pred_forest = forest.predict(X_test)\n",
    "print(\"훈련 : \" , forest.score(X_train , y_train))\n",
    "print(\"테스트 : \" , forest.score(X_test , y_test))\n",
    "print(classification_report(y_test , pred_forest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 :  0.9901144872776164\n",
      "테스트 :  0.880770912978682\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.94    217173\n",
      "           1       0.53      0.08      0.14     29755\n",
      "\n",
      "    accuracy                           0.88    246928\n",
      "   macro avg       0.71      0.54      0.54    246928\n",
      "weighted avg       0.84      0.88      0.84    246928\n",
      "\n",
      "\n",
      "f1 스코어 :  0.14273651107940483\n"
     ]
    }
   ],
   "source": [
    "# 랜덤 포레스트12  \n",
    "\n",
    "forest = RandomForestClassifier(n_estimators = 100 , random_state = 0 , max_features = 2 , max_depth=50)\n",
    "forest.fit(X_train , y_train)\n",
    "pred_forest = forest.predict(X_test)\n",
    "print(\"훈련 : \" , forest.score(X_train , y_train))\n",
    "print(\"테스트 : \" , forest.score(X_test , y_test))\n",
    "print(classification_report(y_test , pred_forest))\n",
    "print(\"\\nf1 스코어 : \" , f1_score(y_test , pred_forest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "행렬 :\n",
      " [[215036   2137]\n",
      " [ 27304   2451]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## 데이터의 DLY 값이 0인 경우가 과하게 많아 분류가 제대로 되지 않는 것을 알 수 있다. -> 비대칭 데이터\n",
    "confusion = confusion_matrix(y_test , pred_forest)\n",
    "print(\"행렬 :\\n\" , confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1303198, 117)\n",
      "(1303198,)\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import *\n",
    "from imblearn.under_sampling import *\n",
    "## DLY가 1인 소수 데이터를 증가시키는 오버 샘플링을 통해 정밀도 precision 향상 시도\n",
    "\n",
    "X_smo_t , y_smo_t = SMOTE(random_state = 0  ).fit_sample(X_train , y_train)\n",
    "\n",
    "print(X_smo_t.shape)\n",
    "print(y_smo_t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 :  0.9972007323522596\n",
      "테스트 :  0.8582258796086308\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.92      0.92    217173\n",
      "           1       0.41      0.40      0.41     29755\n",
      "\n",
      "    accuracy                           0.86    246928\n",
      "   macro avg       0.66      0.66      0.66    246928\n",
      "weighted avg       0.86      0.86      0.86    246928\n",
      "\n",
      "\n",
      "f1 스코어 :  0.407547808427822\n"
     ]
    }
   ],
   "source": [
    "#랜덤포레스트 - class_weight = balanced\n",
    "\n",
    "forest = RandomForestClassifier(n_estimators = 100 , random_state = 0 , max_features = 2 , max_depth=50 , class_weight = 'balanced')\n",
    "forest.fit(X_smo_t, y_smo_t)\n",
    "pred1 = forest.predict(X_test)\n",
    "print(\"훈련 : \" , forest.score(X_smo_t, y_smo_t))\n",
    "print(\"테스트 : \" , forest.score(X_test , y_test))\n",
    "print(classification_report(y_test , pred1))\n",
    "print(\"\\nf1 스코어 : \" , f1_score(y_test , pred1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그래디언트 부스팅 회귀\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gbrt = GradientBoostingClassifier(random_state = 0  , learning_rate = 0.1)\n",
    "gbrt.fit(X_smo_t , y_smo_t , class_weight = 'balanced')\n",
    "pred2 = gbrt.predict(X_test)\n",
    "print(\"  훈련 : \" , gbrt.score(X_smo_t , y_smo_t))\n",
    "print(\"  테스트 : \" , gbrt.score(X_test, y_test))\n",
    "print(classification_report(y_test , pred2))\n",
    "print(\"\\nf1 스코어 : \" , f1_score(y_test , pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 :  0.927317261076214\n",
      "테스트 :  0.8795316853495756\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.94    217173\n",
      "           1       0.56      0.00      0.00     29755\n",
      "\n",
      "    accuracy                           0.88    246928\n",
      "   macro avg       0.72      0.50      0.47    246928\n",
      "weighted avg       0.84      0.88      0.82    246928\n",
      "\n",
      "\n",
      "f1 스코어 :  0.002481472787632876\n"
     ]
    }
   ],
   "source": [
    "# 로지스틱 회귀\n",
    "\n",
    "logreg = LogisticRegression(C = 1).fit(X_smo_t , y_smo_t)\n",
    "pred3 = logreg.predict(X_test)\n",
    "print(\"훈련 : \" , logreg.score(X_smo_t , y_smo_t))\n",
    "print(\"테스트 : \" , logreg.score(X_test , y_test))\n",
    "print(classification_report(y_test , pred3))\n",
    "print(\"\\nf1 스코어 : \" , f1_score(y_test , pred3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 :  0.7063278181826553\n",
      "테스트 :  0.6797366033823625\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.69      0.79    217173\n",
      "           1       0.21      0.62      0.32     29755\n",
      "\n",
      "    accuracy                           0.68    246928\n",
      "   macro avg       0.57      0.65      0.55    246928\n",
      "weighted avg       0.84      0.68      0.73    246928\n",
      "\n",
      "\n",
      "f1 스코어 :  0.31817633162623077\n"
     ]
    }
   ],
   "source": [
    "# 나이브 베이즈 이진분류\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "nb = BernoulliNB(alpha = 100 , class_prior = None,fit_prior=True)\n",
    "nb.fit(X_smo_t , y_smo_t)\n",
    "pred4 = nb.predict(X_test)\n",
    "print(\"훈련 : \" , nb.score(X_smo_t , y_smo_t))\n",
    "print(\"테스트 : \" , nb.score(X_test , y_test))\n",
    "print(classification_report(y_test , pred4))\n",
    "print(\"\\nf1 스코어 : \" , f1_score(y_test , pred4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 :  0.9972705605748321\n",
      "테스트 :  0.8630734465107238\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.94      0.92    217173\n",
      "           1       0.41      0.31      0.36     29755\n",
      "\n",
      "    accuracy                           0.86    246928\n",
      "   macro avg       0.66      0.63      0.64    246928\n",
      "weighted avg       0.85      0.86      0.85    246928\n",
      "\n",
      "\n",
      "f1 스코어 :  0.3556741305383516\n"
     ]
    }
   ],
   "source": [
    "# 랜덤 포레스트2\n",
    "\n",
    "\n",
    "forest = RandomForestClassifier(n_estimators = 20 , random_state = 0)\n",
    "forest.fit(X_smo_t , y_smo_t)\n",
    "pred5 = forest.predict(X_test)\n",
    "print(\"훈련 : \" , forest.score(X_smo_t , y_smo_t))\n",
    "print(\"테스트 : \" , forest.score(X_test , y_test))\n",
    "print(classification_report(y_test , pred5))\n",
    "print(\"\\nf1 스코어 : \" , f1_score(y_test , pred5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 :  0.9809115729152439\n",
      "테스트 :  0.8416906952633966\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.89      0.91    217173\n",
      "           1       0.38      0.48      0.42     29755\n",
      "\n",
      "    accuracy                           0.84    246928\n",
      "   macro avg       0.65      0.68      0.66    246928\n",
      "weighted avg       0.86      0.84      0.85    246928\n",
      "\n",
      "\n",
      "f1 스코어 :  0.4202814729130519\n"
     ]
    }
   ],
   "source": [
    "#랜덤포레스트 - class_weight = balanced\n",
    "\n",
    "forest = RandomForestClassifier(n_estimators = 100 , random_state = 0 , max_features = 2 , max_depth=40 , class_weight = 'balanced')\n",
    "forest.fit(X_smo_t, y_smo_t)\n",
    "pred1 = forest.predict(X_test)\n",
    "print(\"훈련 : \" , forest.score(X_smo_t, y_smo_t))\n",
    "print(\"테스트 : \" , forest.score(X_test , y_test))\n",
    "print(classification_report(y_test , pred1))\n",
    "print(\"\\nf1 스코어 : \" , f1_score(y_test , pred1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 :  0.9936479337752206\n",
      "테스트 :  0.8528801917967991\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.91      0.92    217173\n",
      "           1       0.40      0.44      0.42     29755\n",
      "\n",
      "    accuracy                           0.85    246928\n",
      "   macro avg       0.66      0.67      0.67    246928\n",
      "weighted avg       0.86      0.85      0.86    246928\n",
      "\n",
      "\n",
      "f1 스코어 :  0.4163239074550128\n"
     ]
    }
   ],
   "source": [
    "#랜덤포레스트 - class_weight = balanced\n",
    "\n",
    "forest = RandomForestClassifier(n_estimators = 100 , random_state = 0 , max_features = 2 , max_depth=45 , class_weight = 'balanced')\n",
    "forest.fit(X_smo_t, y_smo_t)\n",
    "pred1 = forest.predict(X_test)\n",
    "print(\"훈련 : \" , forest.score(X_smo_t, y_smo_t))\n",
    "print(\"테스트 : \" , forest.score(X_test , y_test))\n",
    "print(classification_report(y_test , pred1))\n",
    "print(\"\\nf1 스코어 : \" , f1_score(y_test , pred1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 :  0.9933686208849307\n",
      "테스트 :  0.8523739713600725\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.91      0.92    217173\n",
      "           1       0.40      0.43      0.41     29755\n",
      "\n",
      "    accuracy                           0.85    246928\n",
      "   macro avg       0.66      0.67      0.67    246928\n",
      "weighted avg       0.86      0.85      0.86    246928\n",
      "\n",
      "\n",
      "f1 스코어 :  0.4148702226359974\n"
     ]
    }
   ],
   "source": [
    "#랜덤포레스트 - class_weight = balanced\n",
    "\n",
    "forest = RandomForestClassifier(n_estimators = 100 , random_state = 0 , max_features = 1 , max_depth=45 , class_weight = 'balanced')\n",
    "forest.fit(X_smo_t, y_smo_t)\n",
    "pred1 = forest.predict(X_test)\n",
    "print(\"훈련 : \" , forest.score(X_smo_t, y_smo_t))\n",
    "print(\"테스트 : \" , forest.score(X_test , y_test))\n",
    "print(classification_report(y_test , pred1))\n",
    "print(\"\\nf1 스코어 : \" , f1_score(y_test , pred1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 :  0.9929933901064919\n",
      "테스트 :  0.8520094926456295\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.91      0.92    217173\n",
      "           1       0.40      0.44      0.42     29755\n",
      "\n",
      "    accuracy                           0.85    246928\n",
      "   macro avg       0.66      0.67      0.67    246928\n",
      "weighted avg       0.86      0.85      0.86    246928\n",
      "\n",
      "\n",
      "f1 스코어 :  0.4152090767975164\n"
     ]
    }
   ],
   "source": [
    "#랜덤포레스트 - class_weight = balanced\n",
    "#### 최종 선정 ####\n",
    "forest = RandomForestClassifier(n_estimators = 100 , random_state = 0 , max_features = 3 , max_depth=45 , class_weight = 'balanced')\n",
    "forest.fit(X_smo_t, y_smo_t)\n",
    "pred1 = forest.predict(X_test)\n",
    "print(\"훈련 : \" , forest.score(X_smo_t, y_smo_t))\n",
    "print(\"테스트 : \" , forest.score(X_test , y_test))\n",
    "print(classification_report(y_test , pred1))\n",
    "print(\"\\nf1 스코어 : \" , f1_score(y_test , pred1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AFSNT_DLY 원핫인코딩한 X_AFSNT_DLY 읽기\n",
    "\n",
    "DATA2 = pd.read_pickle(\"C:/Users/dong/Desktop/R/data/X_AFSNT_DLY.pkl\")\n",
    "\n",
    "# AFASNT_DLY 읽기\n",
    "DATA3 = pd.read_csv(r\"C:/Users/dong/Desktop/AFSNT_DLY_P.csv\" , encoding = \"CP949\" , sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16076, 117)\n",
      "(16076, 13)\n"
     ]
    }
   ],
   "source": [
    "print(DATA2.shape)\n",
    "print(DATA3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 :  0.9929933901064919\n"
     ]
    }
   ],
   "source": [
    "# AFSNT_DLY에 적용시키기\n",
    "\n",
    "#랜덤포레스트 - class_weight = balanced\n",
    "#### 최종 선정 ####\n",
    "#forest = RandomForestClassifier(n_estimators = 100 , random_state = 0 , max_features = 3 , max_depth=45 , class_weight = 'balanced')\n",
    "#forest.fit(X_smo_t, y_smo_t)\n",
    "pred = forest.predict(DATA2)\n",
    "dly_rate = forest.predict_proba(DATA2)\n",
    "print(\"훈련 : \" , forest.score(X_smo_t, y_smo_t))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16076, 117)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.73200968, 0.26799032])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dly_rate[350]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(DATA3.DLY_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 :  0.9929933901064919\n"
     ]
    }
   ],
   "source": [
    "DATA3['DLY'] = forest.predict(DATA2)\n",
    "DATA3['DLY_RATE'] = forest.predict_proba(DATA2)\n",
    "print(\"훈련 : \" , forest.score(X_smo_t, y_smo_t))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dly_rate2 = forest.predict_proba[0](DATA2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터프레임명.to_csv(\"\")\n",
    "DLY = DATA3['DLY']\n",
    "DLY.to_csv(r\"C:/Users/dong/Desktop/DLY.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "DLY_RATE = DATA3['DLY_RATE']\n",
    "DLY_RATE.to_csv(r\"C:/Users/dong/Desktop/DLY_RATE.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
